{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "ECE595 Hmk 3 Ensemble.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "148mgt8GTZkS",
        "outputId": "7957f46b-4f65-4794-9664-4055c521e9d2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from mlxtend.classifier import EnsembleVoteClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import cifar100\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, BatchNormalization, Dropout\n",
        "from keras import optimizers\n",
        "\n",
        "# import dataset, model and layers  \n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import misc\n",
        "from __future__ import print_function\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "#import splitfolders\n",
        "from keras import Model\n",
        "from keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from keras.layers import ZeroPadding2D\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D,Dropout, Flatten, BatchNormalization, Concatenate, AveragePooling2D\n",
        "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "from keras.datasets import cifar100\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTctUjR8TZkW"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXt5_yNroc1F"
      },
      "source": [
        "batch_size = 32\n",
        "num_classes = 100\n",
        "epochs = 5\n",
        "data_augmentation = True\n",
        "num_predictions = 20"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKLAEWSPTZkW",
        "outputId": "4958d41f-b3a0-4692-d507-c148215af0f9"
      },
      "source": [
        "# example of loading the cifar10 dataset\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "#y_train = y_train.reshape(y_train.shape[0],)\n",
        "#y_test = y_test.reshape(y_test.shape[0],)\n",
        "#x_train = x_train.reshape(x_train.shape[0],(x_train.shape[1] * x_train.shape[2]*x_train.shape[3]))\n",
        "#x_test = x_test.reshape(x_test.shape[0],(x_test.shape[1] * x_test.shape[2]*x_test.shape[3]))\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# plot first few images\n",
        "#for i in range(9):\n",
        "\t# define subplot\n",
        "\t#pyplot.subplot(330 + 1 + i)\n",
        "\t# plot raw pixel data\n",
        "\t#pyplot.imshow(x_train[i])\n",
        "# show the figure\n",
        "#pyplot.show()\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "#y_train.shape\n",
        "#y_test.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 1)\n",
            "(10000, 1)\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgwVwj3PnITR"
      },
      "source": [
        "def resnetmodel():\n",
        "  # load model\n",
        "  model1 = ResNet50(weights='imagenet', include_top=False,input_shape=(32,32,3),classes=num_classes)\n",
        "  # summarize the model\n",
        "  #model.summary()\n",
        "  from keras import models\n",
        "  from keras import layers\n",
        "  from keras import optimizers\n",
        "\n",
        "  # Create the model\n",
        "  modelRes = models.Sequential()\n",
        "\n",
        "  # Add the vgg convolutional base model\n",
        "  modelRes.add(model1)\n",
        "\n",
        "  # Add new layers\n",
        "  modelRes.add(layers.Flatten())\n",
        "  modelRes.add(layers.Dense(1024, activation='relu'))\n",
        "  modelRes.add(layers.Dropout(0.5))\n",
        "  modelRes.add(layers.Dense(num_classes, activation='softmax'))\n",
        "  # Show a summary of the model. Check the number of trainable parameters\n",
        "    # Let's train the model using RMSprop\n",
        "      # initiate RMSprop optimizer\n",
        "  opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "  modelRes.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "  return modelRes"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGXpb7dbTZkX"
      },
      "source": [
        " def mlpmodel(): \n",
        "  weight_decay = 4.7334492434534885e-09\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3,3), padding='same', strides = 1, activation='relu', \n",
        "                  kernel_initializer='he_uniform', \n",
        "                  kernel_regularizer=keras.regularizers.l2(weight_decay), \n",
        "                  ))\n",
        "\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(32, (3,3), padding='same', strides = 1, activation='relu', \n",
        "                  kernel_initializer='he_uniform', \n",
        "                  kernel_regularizer=keras.regularizers.l2(weight_decay))) \n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Conv2D(64, (3,3), padding='same', strides = 1, activation='relu', \n",
        "                  kernel_initializer='he_uniform', \n",
        "                  kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(64, (3,3), padding='same', strides = 1, activation='relu', \n",
        "                  kernel_initializer='he_uniform', \n",
        "                  kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Conv2D(128, (3,3), padding='same', strides = 1, activation='relu', \n",
        "                  kernel_initializer='he_uniform', \n",
        "                  kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(128, (3,3), padding='same', strides = 1, activation='relu', \n",
        "                  kernel_initializer='he_uniform', \n",
        "                  kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(256, (3,3), padding='same', strides = 1, activation='relu', \n",
        "                  kernel_initializer='he_uniform', \n",
        "                  kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.6))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "  adam = optimizers.Adam(lr = 0.0004190581840410445)\n",
        "  model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "  return model\n",
        "    "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e13wfLwWunWO",
        "outputId": "60d0e5b6-3f27-43bc-c5cf-0d08b2658389"
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    history = modelRes.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWxNgt_1TZkX"
      },
      "source": [
        "# create 5 models to ensemble\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "model1 = KerasClassifier(build_fn = resnetmodel, epochs = 20)\n",
        "model1._estimator_type = \"classifier\"\n",
        "model2 = KerasClassifier(build_fn = mlpmodel, epochs = 20)\n",
        "model2._estimator_type = \"classifier\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5YesGURTZkY"
      },
      "source": [
        "ensemble_clf = VotingClassifier(estimators = [('model1', model1), ('model2', model2),], voting = 'soft')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAm826OsTZkY",
        "outputId": "1741bba8-461b-4a84-ec65-6b31df2ff935"
      },
      "source": [
        "ensemble_clf.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 112s 52ms/step - loss: 4.4000 - accuracy: 0.1119\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 80s 51ms/step - loss: 2.5488 - accuracy: 0.3617\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 79s 51ms/step - loss: 2.0439 - accuracy: 0.4669\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 79s 51ms/step - loss: 1.7196 - accuracy: 0.5405\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 80s 51ms/step - loss: 1.5100 - accuracy: 0.5925\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 79s 51ms/step - loss: 1.3165 - accuracy: 0.6393\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 79s 51ms/step - loss: 1.1671 - accuracy: 0.6765\n",
            "Epoch 8/20\n",
            "1205/1563 [======================>.......] - ETA: 18s - loss: 1.0497 - accuracy: 0.7095"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br_Su2vXTZkY"
      },
      "source": [
        "y_pred = ensemble_clf.predict(x_test)\n",
        "print('Acc: ', accuracy_score(y_pred, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}